# InfoCollect

**InfoCollect** Ã¨ un sistema avanzato di raccolta automatica di notizie da fonti RSS e Web, scritto interamente in Perl. Utilizza una pipeline NLP multilingua per analizzare, riassumere e filtrare le notizie in base a interessi predefiniti. Ãˆ pensato per funzionare in modo asincrono, efficiente e configurabile sia da terminale che in modalitÃ  automatica (daemon).

---

## ğŸ§  FunzionalitÃ  principali

- ğŸ“¥ Crawling parallelo da fonti RSS e siti web
- ğŸ§¾ Riassunto automatico dei contenuti tramite NLP (IT/EN)
- ğŸ”’ Autenticazione locale basata sull'utente del sistema operativo
- ğŸ§  Filtraggio intelligente in base a "interessi" personalizzati
- ğŸ—ƒï¸ Archiviazione con metadati completi in SQLite
- ğŸ§ª CLI interattiva per test ed esecuzione manuale
- â²ï¸ ModalitÃ  daemon per raccolta ciclica automatica

---

## ğŸ“¦ Requisiti

- Perl 5.32+
- Moduli Perl (puoi installarli con `modules_installer.pl`):
  - `LWP::UserAgent`, `XML::RSS`, `HTML::TreeBuilder`, `HTML::Strip`
  - `Text::Summarizer`, `Lingua::Identify`, `Lingua::EN::Tagger`, `Lingua::IT::Stemmer`
  - `Term::ReadLine`, `Term::ANSIColor`, `Parallel::ForkManager`, `DBI`, `DBD::SQLite`, `Time::HiRes`

---

## ğŸš€ Avvio rapido

```bash
perl modules_installer.pl   # Installa i moduli necessari
perl start.pl               # Avvia la CLI interattiva
```

Oppure in modalitÃ  automatica:

```bash
perl agent.pl 15   # Avvia raccolta automatica ogni 15 minuti
```

---

## ğŸ’» CLI interattiva

Comandi disponibili:

- `rss-crawl` â€“ Avvia il crawler RSS
- `web-crawl` â€“ Avvia il crawler Web
- `run-all` â€“ Avvia entrambi
- `loop <min>` â€“ Avvia raccolta automatica ogni N minuti
- `add-setting <k> <v>` â€“ Aggiungi impostazioni
- `get-setting <k>` â€“ Leggi impostazioni
- `delete-setting <k>` â€“ Rimuovi impostazioni
- `exit` / `quit` â€“ Esci dalla CLI

---

## ğŸ—ƒï¸ Database

Il database `infocollect.db` contiene:

- `settings` â€“ Configurazioni generali
- `rss` e `web` â€“ Fonti attive
- `interessi` â€“ Parole chiave da monitorare
- `riassunti` â€“ Contenuti rilevanti riassunti e con metadati
- `pages`, `rss_articles`, `rss_feeds` â€“ Archiviazione completa

---

## ğŸ“‚ Struttura del progetto

```
InfoCollect/
â”œâ”€â”€ start.pl
â”œâ”€â”€ agent.pl
â”œâ”€â”€ info_collect.pl
â”œâ”€â”€ modules_installer.pl
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ rss_crawler.pm
â”‚   â”œâ”€â”€ web_crawler.pm
â”‚   â”œâ”€â”€ nlp.pm
â”‚   â”œâ”€â”€ init_db.pm
â”‚   â”œâ”€â”€ config_manager.pm
â”‚   â”œâ”€â”€ interactive_cli.pm
â”‚   â””â”€â”€ ...
â”œâ”€â”€ infocollect.db
â”œâ”€â”€ Feeds.opml (opzionale)
â””â”€â”€ README.md
```

---

## ğŸ”’ Autenticazione

InfoCollect supporta due metodi di autenticazione:

1. **Token API**: Configurabile tramite la variabile d'ambiente `INFOCOLLECT_API_TOKEN`.
2. **Autenticazione locale**: L'accesso Ã¨ consentito all'utente locale che esegue lo script, determinato dinamicamente tramite le funzioni del sistema operativo.

---

## ğŸ“ Licenza

Distribuito sotto licenza BSD. Vedi intestazione dei file per i dettagli.
